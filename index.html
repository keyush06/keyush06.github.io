<!DOCTYPE html>
<html>

<head>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link rel="stylesheet" href="style.css">
	<title>Keyush Shah</title>

	
</head>

<body>
	<img id="profile_pic" src="assets/Pinpoint_DSC_0590.jpg" alt="Keyush">

	<h1>Keyush Shah</h1>

	<h3>
		<a href="assets/Resume__Keyush_HTMRe.pdf" class="red-link">Resume</a>
		| <a href="https://scholar.google.com/citations?user=MLffnpkAAAAJ&hl=en" class="red-link">Google Scholar</a>
		| <a href="https://github.com/keyush06" class="red-link">Github</a>
		| <a href="mailto:keyush.shah12@gmail.com" class="red-link">Email ID</a>
	</h3>
	

	<br>

	<p>
	Hello, I am a second year graduate student at the University of Pennsylvania pursuing MSE in Data Science. My academic journey began with a strong foundation Statistics and Mathematics where I developed the acumen in Analytics, Inference and data driven modeling - it laid the groundwork
	for my foray into Data Science. Now I am focused on exploring the vast potential of Generative AI and Machine Learning in solving real-world challenges and leveraging data to drive impactful insights.
</p>

<p>
	I have hands-on experience in the field of Generative AI, working with deep learning architectures and generative models for various applications.
	<ul>
			

		<li>
			My proficiency spans:
			<ul>
				<li><strong>Natural Language Processing (NLP)</strong> – including large language models, text generation, and sentiment analysis.</li>
				<li><strong>Computer Vision (CV)</strong> – experience in image segmentation, object detection, and image synthesis tasks.</li>
			</ul>
		</li>
		<li>
			I have been deeply interested in the fusion of modalities and am currently exploring the multimodal space, especially Vision-Language Models.
		</li>
		<li>
			Additionally, I have experience with <strong><u>data engineering</u></strong> tools and cloud platforms, particularly the <strong>Azure suite and AWS</strong>, utilizing services such as Azure Data Factory, Azure Databricks and AWS Sagemaker to build scalable data pipelines and ML models for AI-driven applications.
		</li>
	</ul>

	<h3> <u>Kindly take a look at my <a href="#portfolio">Portfolio of Projects</a>.</u></h3>
</p>
<!-- <br> -->
	
	
	
<h2>Research</h2> 

Click the link below to take a look at my research interests and some questions that interest me.
<br>
<br>

	

	<!-- <section id="researchSection" style="display: none;"> -->
		<h3 onclick="toggleSection()" 
    style="text-decoration: underline; color: white; 
           cursor: pointer; text-align: center; 
           background-color: #063e75; padding: 15px; 
           border-radius: 8px; width: 50%; 
           margin: auto; font-size: 20px;">
    Research Interests
</h3>
<br>
<section id="researchSection" style="display: none; text-align: left; margin-top: 20px;">
    <div style="width: 60%; margin: auto; padding: 15px; border: 2px solid #808080; border-radius: 8px; background-color: #f9f9f9;">
			<p>
				<strong>1. Vision-Language Understanding:</strong> I am interested in pursuing research on enhancing 
				<strong>Vision-Language Models (VLMs)</strong> through Representation Learning and Transfer Learning, 
				with a focus on <strong>Compositionality</strong>, <strong>Alignment</strong>, and <strong>Grounding</strong> 
				to better integrate visual and textual data.
			</p>
		
			<p>
				<strong>2. Responsible VLMs:</strong> I aim to explore ways to address biases and hallucinations in 
				VLMs by establishing benchmarks for fairer and more ethical systems, contributing to the 
				development of inclusive and trustworthy Social AI.
			</p>
		
			<p>
				<strong>3. Datasets and Synthetic Data:</strong> I am keen on investigating the role of datasets in building 
				VLMs, particularly the potential of synthetic data generation to overcome limitations and 
				enable diverse, scalable, and high-quality training resources.
			</p>
	</section>
	
	<script>
		function toggleSection() {
			var section = document.getElementById("researchSection");
			if (section.style.display === "none") {
				section.style.display = "block";
			} else {
				section.style.display = "none";
			}
		}
	</script>

I am a Research Assistant at the <a href="https://csl-lab-upenn.github.io/">Computational Social Listening Lab</a> 
where I am advised by Prof. <a href="https://www.cis.upenn.edu/~ungar/">Lyle Ungar</a> and Prof. <a href="https://sharathg.cis.upenn.edu/">Sharath Guntuku</a>. My research projects are aimed at the intersection of AI, Healthcare and Social Science that align with my interests. 
I apply NLP, machine learning, and data analytics to problems like predicting patient outcomes, analyzing healthcare disparities, and understanding mental health trends. 
My work goes beyond research—it's about leveraging technology to drive real impact, improving decision-making and accessibility in the healthcare industry.

Check out my ongoing projects in the section below.
</p>


	<div style="border: 2px solid #808080; padding: 15px; margin: 20px 0; border-radius: 8px;">
		<h3 style="background-color: #FFD700; color: black; margin: -15px -15px 10px -15px; padding: 10px; border-radius: 8px 8px 0 0; text-align: center; font-size: 1.2em;">
			Current Research Projects
		</h3>
        <p>
			
			<ul> 
				<li>
					<u><strong>IH Risk Model: </strong></u><br> In collaboration with <strong> Penn Medicine</strong>, I am working on developing a model to predict the risk of Incisional Hernia (IH) in patients post-surgery by using real-world operative notes and intraoperative EHR data.
					By leveraging machine learning (ML) and NLP, our model analyzes surgical technique, procedural factors, and patient physiology to provide personalized, data-driven insights. This helps surgeons make better decisions, reduce complications, and improve patient outcomes.

				</li>
				<li>
					<u><strong>Misinformation: </strong></u><br>
					<ul>
						<li><u><strong>Research Goal:</strong></u> Working on identifying misinformation on social media (FB posts, YouTube interactions) and whether or not it relates to health outcomes for people categorized on the basis of race (white/black) & urbanity (rural/urban).</li>
						
						<li>Developed a URL based misinformation-detection model that detected around 1k misinformed posts out of 1mm FB posts.</li>
						
						<li>Implemented semantic similarity and entailment analysis using a pre-trained <strong>RoBERTa</strong> model to detect misinformation based on post alignment with trusted claims.</li>
						
						<li>Extracted linguistic features from posts using <strong><a href="https://dlatk.github.io/dlatk/tutorials.html" target="_blank">DLATK</a></strong> and applied LDA for topic modeling- computed Pearson’s Correlation for these topic distributions with depression scores computed from user surveys to identify key linguistic markers.</li>
						
						<li>Implemented sentiment analysis using a pre-trained ‘DistilBERT’ Transformer model to evaluate user emotions from social media posts, leading to insights on engagement patterns segmented by race and urbanity.</li>
						
						<li>Unified data from various online survey platforms in a secured server via MySQL and performed feature engineering in Pandas to prepare data for further downstream tasks.</li>
					</ul>
					
				</li>
				

				<li>

					<u><strong>"Agency" determination using NLP:  </strong></u> <br> In collaboration with the <Strong>Department of Psychology</Strong> at Penn, I aim to analyze the evolution of male and female <a href = "https://en.wikipedia.org/wiki/Agency_(psychology)">"Agency"</a> in historical texts using AI and NLP. Our multi-source dataset—magazines, movie scripts, and NYT bestsellers—is processed with OCR and SpaCy to extract linguistic structures. 
					Leveraging GPT, we aim label agents (action-takers) and patients (acted-upon entities), revealing gendered patterns over time. This data-driven approach uncovers shifts in societal narratives, offering deep insights into cultural and historical trends.
				</li>

			</ul>
		
        </p>
    </div>


	<!-- <div style="border: 2px solid #808080; padding: 15px; margin: 20px 0; border-radius: 8px;">
		<h3 style="background-color: #003366; color: white; margin: -15px -15px 10px -15px; padding: 10px; border-radius: 8px 8px 0 0; text-align: center; font-size: 1.2em;">
			Deviating from AI
		</h3>
		<p>
			On the business end, I am familiar with leveraging statistical models to drive impactful business decisions, 
			such as predicting customer lifetime value (CLV), performing customer segmentation, and developing forecasting models. 
			Courses like Applied Statistical Models in Modelling at Wharton equipped me with advanced techniques for building 
			behaviorally plausible models to explain and predict consumer patterns.
		</p>
	</div> -->
	<!--<p>-->
	<!--I am interested in deep learning research, with a recent focus on foundation models. In my past work, I have enjoyed forays into noisy data learning, graph ML, neuro-symbolic AI, and program analysis.-->
	<!--</p>-->

	<!-- <h2>news</h2>

	<table>

	<tr>
		<th>Jul 30, 2024</th>
		<td><a href="https://relbench.stanford.edu">RelBench</a> (v1) released.</td>
	</tr>

	<tr>
		<th>May 1, 2024</th>
		<td>Our <a href="assets/2024_icml_rdl/paper.pdf">Relational Deep Learning</a> position paper was accepted at ICML 2024.</td>
	</tr>

	<tr>
		<th>Apr 11, 2024</th>
		<td>My CMU work on <a href="https://arxiv.org/abs/2404.07815">Post-Hoc Reversal</a> is on arXiv.</td>
	</tr>

	<tr>
		<th>Mar 18, 2024</th>
		<td>I aligned with Prof. <a href=https://cs.stanford.edu/people/jure/">Jure Leskovec</a> as my PhD advisor.</td>
	</tr>

	<tr>
		<th>Nov 28, 2023</th>
		<td>Our <a href="https://arxiv.org/abs/2312.04615">Relational Deep Learning</a> paper was on the front page of <a href="https://news.ycombinator.com/item?id=38447338">Hacker News</a>.</td>
	</tr>

	<tr>
		<th>Nov 27, 2023</th>
		<td><a href="https://relbench.stanford.edu">RelBench</a> (Beta) released at Learning on Graphs (LoG) conference.</td>
	</tr>

	<tr>
		<th>Sep 26, 2023</th>
		<td>I started my PhD at Stanford.</td>
	</tr>

	<tr>
		<th>Jul 15, 2023</th>
		<td>This webpage is live.</td>
	</tr>

	</table> -->

	<h2>Professional Experience</h2>

	<ol class="horizontal-list">
		
		<li>
			<h3><a href="assets/Resume__Keyush_HTMRe.pdf"">CSL Lab</a></h3>
			<i>Research Assistant</i>
			<i>2024</i>
		</li>

		<li>

			<h3><a href="assets/Resume__Keyush_HTMRe.pdf"">Universal Media</a></h3>
			<i>Data Science Intern</i>
			<i>2024</i>
		</li>
		
		<li>
			<h3><a href="assets/Resume__Keyush_HTMRe.pdf"">IIFL Finance Ltd</a></h3>
			<i>Assistant Manager</i>
			<i>2022 - 2023</i>
		</li>
	</ol>
	
	


	<h2>Publication: pre-prints</h2>

	(* denotes equal contribution)

	<ol>
	
	<li>
		<b>Enhancing Retrieval in QA Systems with Derived Feature Association</b><br>
		<u>Keyush Shah</u>, <u>Abhishek Goyal*</u>, <u>Isaac Wasserman*</u><br>
		<i>arXiv preprint, 2024</i><br>

		<a href="assets/neurips_2023.pdf">paper</a>
		| <a href="https://arxiv.org/abs/2410.03754">arxiv</a>
		| <a href="https://github.com/isaacwasserman/LongRAG">code</a>
		<!-- | <a href="https://relbench.stanford.edu">website</a> -->
		<!-- | <a href="assets/2024_arxiv_relbench/cite.txt">cite</a> -->
	</li>

	<!-- <li>
		<b>Post-Hoc Reversal: Are We Selecting Models Prematurely?</b><br>
		<u>Rishabh Ranjan</u>, Saurabh Garg, Mrigank Raman, Carlos Guestrin, Zachary Lipton<br>
		<i>arXiv preprint, 2024</i><br>

		<a href="assets/2024_arxiv_phr/paper.pdf">paper</a>
		| <a href="https://arxiv.org/abs/2404.07815">arxiv</a>
		| <a href="https://github.com/rishabh-ranjan/post-hoc-reversal">code</a>
		| <a href="assets/2024_arxiv_phr/cite.txt">cite</a>
	</li> -->

	</ol>

	<h2 id = "portfolio">Portfolio of Selected Projects</h2>

	<!-- Deep Learning Section -->
	<div>
		<h3 style="display: inline-block; padding: 5px 10px; background-color: #509250; color: white; border-radius: 5px;">
			Deep Learning
		</h3>
		<ul>

			<li>
				<h4>Computer Vision</h4>
				<ul>
					<li><a href="#instance-segmentation">Instance Segmentation: By Location</a></li>
					<li><a href="#depth">Improving Depth Estimation of DinoV2</a></li>
				</ul>
			</li>
			<li>
				<h4>MultiModal</h4>
				<ul>
					
					<li><a href="#image-reconstruction">Image Reconstruction using Diffusion Transformers</a></li>
					<li><a href="#deep">Deepfake Detection</a></li>
				</ul>
			</li>
			<li>
				<h4>Computational Linguistics/NLP</h4>
				<ul>
					<!-- <li><a href="#misinfo">Misinformation Research</a></li> -->
					<li><a href="#lda">Topic-Modelling-with-Latent-Dirichlet-Allocation</a></li>

				</ul>
			</li>


		</ul>
	</div>
	
	<!-- Traditional Machine Learning Section -->
	<div>
		<h3 style="display: inline-block; padding: 5px 10px; background-color: #509250; color: white; border-radius: 5px;">
			Traditional Machine Learning
		</h3>
		<ul>
			<li><a href="#pricePrediction">Bangalore House Prediction</a></li>
			
		</ul>
	</div>
	
	<!-- Computer Vision Section -->
	<div>
		<h3 style="display: inline-block; padding: 5px 10px; background-color: #509250; color: white; border-radius: 5px;">
			AI Engineering/LLMs
		</h3>
		<ul>
			<li><a href="#fitbit">FitBit ChatBot</a></li>
		</ul>
	</div>
	
	<!-- Data Engineering Section -->
	<div>
		<h3 style="display: inline-block; padding: 5px 10px; background-color: #509250; color: white; border-radius: 5px;">
			Data Engineering/Databases & Information Systems
		</h3>
		<ul>
			<li><a href="#db">Scalable ETL Pipelines with Microsoft Azure</a></li>
		</ul>
	</div>
	
	<!-- Probability and Statistical Modeling Section -->
	<div>
		<h3 style="display: inline-block; padding: 5px 10px; background-color: #509250; color: white; border-radius: 5px;">
			Probability & Statistical Modeling
		</h3>
		<ul>
			<li><a href="#CLV">CLV Projects</a></li>
		</ul>
	</div>
	
	


	<h2>Project Descriptions</h2>

	<!-- (* denotes equal contribution) -->

	<ol>

		<li id="image-reconstruction">
			<h3>Image Reconstruction using Diffusion Transformers</h3>
			<img src="assets\celeb_diffusion.jpeg" alt="DiT pic" style="width:450px;"><br>
			I developed a PatchVAE model to encode facial features from the CelebA dataset, followed by training a Diffusion model using the VAE's latent representations. This approach successfully reconstructed and generated realistic human face images. The model achieved an impressive FID score of 14.2, highlighting its effectiveness in producing high-quality outputs.<br>
			<!-- <i>International Conference on Machine Learning (ICML), 2024</i><br> -->
	
			<!-- <a href="assets/2024_icml_rdl/paper.pdf">paper</a>
			| <a href="https://arxiv.org/abs/2312.04615">arxiv</a> -->
			| <a href="https://github.com/keyush06/DiT-Diffusion-Transformers">code</a>
			| <a href="https://arxiv.org/abs/2212.09748">Reference Paper</a>
	
			<!-- | <a href="https://relbench.stanford.edu">website</a>
			| <a href="assets/2023_icml_rdl/cite.txt">cite</a> -->
		</li>

	<li  id="instance-segmentation">
		<h3>Instance Segmentation: By location</h3>
		<img src="assets\ins_segmentation.jpeg" alt="Intsance Segmentation Pic" style="width:450px;"><br>
		I implemented an advanced instance segmentation framework inspired by the SOLO (Segmenting Objects by Locations) model. It features a ResNet backbone for robust feature extraction and a Feature Pyramid Network (FPN) to handle multi-scale object representations efficiently.

		The architecture consists of two main branches. The Category Prediction Branch assigns pixels to grid-based instance categories, leveraging spatial information to effectively localize and distinguish objects of varying sizes. 
	<p>Meanwhile, the Mask Segmentation Branch generates accurate binary masks using a spatially sensitive, fully convolutional network, eliminating the need for traditional bounding boxes or complex post-processing.

		This end-to-end trainable system simplifies the segmentation pipeline, learning directly from mask annotations to enhance efficiency and deliver high performance across diverse object segmentation tasks.</p> <br>
		<!-- <i>International Conference on Machine Learning (ICML), 2024</i><br> -->

		<!-- <a href="assets/2024_icml_rdl/paper.pdf">paper</a>
		| <a href="https://arxiv.org/abs/2312.04615">arxiv</a> -->
		| <a href="https://github.com/keyush06/Segmenting-Objects-by-Location">code</a>
		| <a href="https://arxiv.org/abs/2106.15947">Reference Paper</a>

		<!-- | <a href="https://relbench.stanford.edu">website</a>
		| <a href="assets/2023_icml_rdl/cite.txt">cite</a> -->
	</li>


	<li  id="depth">
		<h3>Improving Depth Estimation of DinoV2</h3>
		<img src="assets\de.jpeg" alt="depth estimation pic" style="width:450px;"><br>
		<p>The research demonstrated that combining temporal information across frames reduces per-frame errors, enhancing the scaling accuracy of depth maps.  The project explored methods to improve depth estimation in DINOv2 using iterative strategies. Initially, ORB features and phase correlation were applied to align depth maps of consecutive frames explicitly. This approach leveraged the spatial shifts between frames to average depth maps and achieved modest reductions in MSE with minimal latency. However, limitations in alignment accuracy due to perspective distortions motivated further refinement.</p>

		<p>Subsequently, a CNN-based adapter was integrated between the DINOv2 encoder and depth adapter. This adapter utilized phase-correlation-derived pixel shifts as additional input to adjust and combine DINO features from consecutive frames. The CNN introduced an inductive bias for local feature alignment, leading to a significant 23.8% reduction in MSE, outperforming vanilla DINOv2-base while being faster. Regularization techniques were later introduced to preserve high-resolution details in depth maps, improving output quality while maintaining accuracy.</p>
		<br>
		<!-- <i>International Conference on Machine Learning (ICML), 2024</i><br> -->

		<!-- <a href="assets/2024_icml_rdl/paper.pdf">paper</a>
		| <a href="https://arxiv.org/abs/2312.04615">arxiv</a> -->
		| <a href="https://github.com/keyush06/Improving-DINOv2-Depth-Estimates-by-Smoothing-Over-Consecutive-Frames">code</a>
		| <a href="https://github.com/keyush06/Improving-DINOv2-Depth-Estimates-by-Smoothing-Over-Consecutive-Frames/blob/master/Dino%20Features%20Research.pdf">Reference Paper</a>

		<!-- | <a href="https://relbench.stanford.edu">website</a>
		| <a href="assets/2023_icml_rdl/cite.txt">cite</a> -->
	</li>

	<li id="fitbit">

		<h3>FitBit</h3>
		<img src="assets\health Chatbot.jpeg" alt="healthcare bot" style="width:550px;"><br>
		Designed and developed a Django-based AI chatbot for health-related conversations, integrating PostgreSQL for robust patient data management and Langchain for LLM-agnostic model orchestration. Implemented dynamic entity extraction to capture key details like medications and appointment preferences, optimized memory usage for long conversations, and enabled automated escalation of appointment and treatment requests.  <br>
		<!-- <i>International Conference on Machine Learning (ICML), 2024</i><br> -->

		<!-- <a href="assets/2024_icml_rdl/paper.pdf">paper</a>
		| <a href="https://arxiv.org/abs/2312.04615">arxiv</a> -->
		| <a href="https://github.com/keyush06/FitBit_ChatBot">Github code</a>
		<!-- | <a href="https://arxiv.org/abs/2106.15947">Reference Paper</a> -->


	</li>

	<li id="db">

		<h3>Scalable ETL Pipelines with Microsoft Azure</h3>
		<img src="assets\deng.jpeg" alt="data eng img" style="width:600px;"><br>
		<p>In this project, I implemented a robust ETL (Extract, Transform, Load) pipeline using Azure cloud services to process and analyze data efficiently. The pipeline began with data ingestion from HTTP sources and SQL databases. Using Azure Data Factory (ADF), I created linked services to connect to these data sources and developed data pipelines to 
		automate the extraction of raw data. The ingested data was stored in Azure Data Lake Storage Gen2 (ADLS Gen2) as the raw data layer.</p>
	<p>For data transformation, I utilized Azure Databricks, where the raw data was processed through data cleansing, aggregation, 
		and feature engineering to prepare it for downstream analysis. The transformed data was then stored back in ADLS Gen2 in a structured format.
		Finally, the processed data was imported into Azure Synapse Analytics, where it was further analyzed. This comprehensive ETL pipeline 
		enabled seamless data movement and transformation, leveraging Azure's ecosystem for efficient data processing and analysis. </p> <br>
		<!-- <i>International Conference on Machine Learning (ICML), 2024</i><br> -->

		<!-- <a href="assets/2024_icml_rdl/paper.pdf">paper</a>
		| <a href="https://arxiv.org/abs/2312.04615">arxiv</a> -->
		| <a href="https://github.com/keyush06/ETL-with-Azure-Data-Factory">Github code</a>
		<!-- | <a href="https://arxiv.org/abs/2106.15947">Reference Paper</a> -->


	</li>

	
	<li id="deep">

		<h3>Deepfake Detection</h3>
		<img src="assets\deep.jpeg" alt="deepfake pic" style="width:600px;"><br>
		Deepfake detection research focuses on identifying and analyzing manipulated video content generated using advanced generative models. By curating extensive video datasets and developing innovative annotation frameworks, 
		researchers aim to refine the detection of both visual and temporal artifacts. State-of-the-art Video Vision-Language Models (VLMs) such as 
		VideoLaMA, BLIP, and LLaVA are evaluated by integrating synthetic data and annotated explanations to enhance the categorization of artifacts and improve detection accuracy. Additionally, methodologies like 
		Kendall Tau’s correlation and reliability analysis are employed to verify data and align annotations. These techniques help assess inter-annotator agreement on deformation labels, 
		providing robust benchmarks for evaluating the performance of current state-of-the-art detection models.
		<br>
		<!-- <i>International Conference on Machine Learning (ICML), 2024</i><br> -->

		<!-- <a href="assets/2024_icml_rdl/paper.pdf">paper</a>
		| <a href="https://arxiv.org/abs/2312.04615">arxiv</a> -->
		| <a href="https://github.com/keyush06/Deepfake-Detection">Github code</a>
		<!-- | <a href="https://arxiv.org/abs/2106.15947">Reference Paper</a> -->


	</li>




	<!-- add this only when needed -->
	<!-- <li>
		<h3>Marvel Bot</h3>
		<img src="assets/marvel.jpeg" alt="Marvel Image" style="width:300px;"><br>
		Engineered a conversational LLM app using LangChain and RAG, integrating Ollama to optimize three quantized models. Web scraped 4+ Marvel Wikipedia pages and deployed the solution on Streamlit, ensuring real-time, context-aware responses and efficient memory usage. <br>
		 <i>International Conference on Machine Learning (ICML), 2024</i><br> -->

		<!-- <a href="assets/2024_icml_rdl/paper.pdf">paper</a>
		| <a href="https://arxiv.org/abs/2312.04615">arxiv</a> -->
		<!-- | <a href="https://github.com/keyush06/Marvel-bot-Conversational-RAG-based-LLM-application">code</a> -->
		<!-- | <a href="https://relbench.stanford.edu">website</a>
		| <a href="assets/2023_icml_rdl/cite.txt">cite</a> -->
	<!-- </li> -->

	<li id="traversability-estimation">
		<h3>Traversability Estimation</h3><br>
		<img src="assets/OffRoadNavigation.jpeg" alt="Terrain Image" style="width:600px;"><br>
		Developed a terrain classification model using Semantic Segmentation and an attention enhanced Fully Convolutional Network, achieving a 2% improvement in IoU. Enhanced off-road navigation for autonomous 
		vehicles by optimizing path planning and terrain adaptability.<br>
		<!-- <i>Advances in Neural Information Processing Systems (NeurIPS), 2022</i><br> -->

		<a href="assets/Traversability Estimation/Report.pdf">paper</a>
		| <a href="assets/Traversability Estimation/Pyramid_pool_Final.ipynb">code</a>
		<!-- | <a href="https://openreview.net/forum?id=EqZuN4V_FLF">reviews</a>
		| <a href="https://neurips.cc/media/PosterPDFs/NeurIPS%202022/53251.png?t=1669859105.1475148">poster</a>
		| <a href="https://neurips.cc/virtual/2022/poster/53251">slides</a>
		| <a href="https://github.com/dair-iitd/ilploss">code</a>
		| <a href="assets/2022_neurips_ilploss/cite.txt">cite</a> -->
	</li>

	
	<li id="pricePrediction">
		<h3>Bangalore House Prediction</h3><br>
		<img src="assets/house.png" alt="house Image" style="width:600px;"><br>
		In this project, a machine learning model was developed to predict house prices in Bangalore using the sklearn library. The dataset was sourced from Kaggle and preprocessed using NumPy and Pandas for data cleaning, including outlier detection, feature engineering, and dimensionality reduction. The model was built using linear regression, with hyperparameter 
		tuning implemented through GridSearchCV and performance evaluated using k-fold cross-validation.
	<p>The application was powered by a Flask server, which acted as the backend to handle HTTP requests. The Flask server loaded the saved machine learning model and processed user inputs like square footage and number of bedrooms to return predicted prices. 
		A front-end interface was built using HTML, CSS, and JavaScript, allowing users to 
		input property details and retrieve price predictions dynamically via calls to the Flask API. The entire workflow integrated Python-based tools and libraries, offering a robust and user-friendly application for real estate price prediction.</p> <br>
		<!-- <i>Advances in Neural Information Processing Systems (NeurIPS), 2022</i><br> -->

		<!-- <a href="assets/Traversability Estimation/Report.pdf">paper</a> -->
		| <a href="https://github.com/keyush06/Bangalore-HomePrice-prediction">code</a>
		<!-- | <a href="https://openreview.net/forum?id=EqZuN4V_FLF">reviews</a>
		| <a href="https://neurips.cc/media/PosterPDFs/NeurIPS%202022/53251.png?t=1669859105.1475148">poster</a>
		| <a href="https://neurips.cc/virtual/2022/poster/53251">slides</a>
		| <a href="https://github.com/dair-iitd/ilploss">code</a>
		| <a href="assets/2022_neurips_ilploss/cite.txt">cite</a> -->
	</li>

	<li id="lda">
		<h3>Topic-Modelling-with-Latent-Dirichlet-Allocation</h3><br>
		<img src="assets/lda.png" alt="lda Image" style="width:600px;"><br>
		This project focuses on implementing Latent Dirichlet Allocation (LDA) for topic modeling, a natural language processing technique that classifies text into topics based on the corpus's underlying word distributions. Using libraries like NLTK, Gensim, and SpaCy, text preprocessing involved cleaning data with RegEx and preparing it for analysis.

		Key steps included generating word clouds to visualize word frequency distributions, computing coherence and perplexity scores to optimize the number of topics, and identifying the dominant topic for each document along with its percentage contribution. 
		The LDA model revealed the proportion of documents belonging to the top six dominant topics, facilitating 
		deeper insights into the dataset's structure. Interactive visualizations further enhanced the interpretability of the results, making the analysis accessible and insightful. This project demonstrated a robust approach to uncovering hidden thematic patterns in text data.<br>
				<!-- <i>Advances in Neural Information Processing Systems (NeurIPS), 2022</i><br> -->

		<!-- <a href="assets/Traversability Estimation/Report.pdf">paper</a> -->
		| <a href="https://github.com/keyush06/Topic-Modelling-with-Latent-Dirichlet-Allocation-LDA-">code</a>
		<!-- | <a href="https://openreview.net/forum?id=EqZuN4V_FLF">reviews</a>
		| <a href="https://neurips.cc/media/PosterPDFs/NeurIPS%202022/53251.png?t=1669859105.1475148">poster</a>
		| <a href="https://neurips.cc/virtual/2022/poster/53251">slides</a>
		| <a href="https://github.com/dair-iitd/ilploss">code</a>
		| <a href="assets/2022_neurips_ilploss/cite.txt">cite</a> -->
	</li>


	<!-- <li>
		<b>GREED: A Neural Framework for Learning Graph Distance Functions</b><br>
		<u>Rishabh Ranjan</u>, Siddharth Grover, Sourav Medya, Venkatesan Chakaravarthy, Yogish Sabharwal, Sayan Ranu<br>
		<i>Advances in Neural Information Processing Systems (NeurIPS), 2022</i><br>

		<a href="assets/2022_neurips_greed/paper.pdf">paper</a>
		| <a href="https://arxiv.org/abs/2112.13143">arxiv</a>
		| <a href="https://openreview.net/forum?id=3LBxVcnsEkV">reviews</a>
		| <a href="https://neurips.cc/media/PosterPDFs/NeurIPS%202022/54507.png?t=1669859442.0786178">poster</a>
		| <a href="https://neurips.cc/virtual/2022/poster/54507">slides</a>
		| <a href="https://github.com/idea-iitd/greed">code</a>
		| <a href="assets/2022_neurips_greed/cite.txt">cite</a>
	</li>

	<li>
		<b>Exploiting Epochs and Symmetries in Analysing MPI Programs</b><br>
		<u>Rishabh Ranjan</u>, Ishita Agrawal, Subodh Sharma<br>
		<i>IEEE/ACM International Conference on Automated Software Engineering (ASE), 2022</i><br>


		<a href="assets/2022_ase_simian/paper.pdf">paper</a>
		| <a href="https://github.com/rishabh-ranjan/simian">code</a>
		| <a href="https://sat-smt-ws.gitlab.io/2020/programme.html">talk</a>
		| <a href="assets/2022_ase_simian/cite.txt">cite</a>
	</li> -->

	</ol>


	<footer>
		Made with &#10084;&#65039; in plain HTML and CSS code

		<!-- Made with &#10084;&#65039; in plain HTML and CSS (<a href="https://github.com/rishabh-ranjan/rishabh-ranjan.github.io">code</a>). -->
	<footer>
</body>

</html>
